{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 6 Exercises\n",
    "\n",
    "_McKinney 6.1_\n",
    "\n",
    "There are multiple ways to solve the problems below.  You can use any one of several approaches.  For example, you can read CSV files using Pandas or the csv module.  Your score won't depend on which modules you choose to use unless explicitly noted below, but your programming style will still matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.1 List of Allergies\n",
    "\n",
    "In the /data directory on the Jupyter server, there is a file called `allergies.json` that contains a list of patient allergies.  It is taken from sample data provided by the EHR vendor, Epic, here: https://open.epic.com/Clinical/Allergy\n",
    "\n",
    "Take some time to look at the structure of the file.  You can open it directly in Jupyter by clicking the _Home_ icon, then the _from_instructor_ folder, and then the _data_ folder.\n",
    "\n",
    "Within the file, you'll see that it is a dictionary with many items in it.  One of those items is called `entry` and that item is a list of things.  You can tell that because the item name is immediately followed by an opening square bracket, signifying the start of a list.  It's line 11 of the file: `  \"entry\": [`\n",
    "\n",
    "Write a function named `allergy_count(json_file)` that takes as one parameter the name of the JSON file and returns an integer number of entries in that file.  Your function should open the file, read the json into a Python object, and return how many items there are in the list of `entry`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "ALLERGIES_FILE=\"/data/allergies.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_count(json_file):\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    return(len(allergies.get('entry')))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergy_count(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q1-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(allergy_count(ALLERGIES_FILE)) == int\n",
    "assert allergy_count(ALLERGIES_FILE) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.2 Number of Patients\n",
    "\n",
    "If you dig a little bit deaper into this list of allergies, you'll see that each result has a patient associated with it.  Create a funcation called `patient_count(json_file)` that will count how many unique patients we have in this JSON structure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def patient_count(json_file):\n",
    "    patients = set()\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        resource = entry.get('resource')\n",
    "        patient = resource.get('patient')\n",
    "        name = patient.get('display')\n",
    "        patients.add(name)\n",
    "        \n",
    "    return patients\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_count(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.3 How Many Allergies per Patient\n",
    "\n",
    "Although each entry is a separate allergy, several of them are for the same patient.  Write a function called `allergy_per_patient(json_file)` that counts up how many allergies each patient has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def allergy_per_patient(json_file):\n",
    "    patients = {}\n",
    "    with open(json_file) as f:\n",
    "        allergies = json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        resource = entry.get('resource')\n",
    "        patient = resource.get('patient')\n",
    "        name = patient.get('display')\n",
    "        patients[name] = patients.setdefault(name,0) + 1\n",
    "        \n",
    "    return patients\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergy_per_patient(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-question",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.4 Patient Allergies and Reaction\n",
    "\n",
    "You'll see in the file that each of the items in the `entry` list have several other attributes including a patient name, substance text representation, and a reaction manifestation.  Create a function named `allergy_list(json_file)` that will create an output list that has patient name, allergy, and reaction for each `entry`.  The actual result you should get will be:\n",
    "\n",
    "```python\n",
    "[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
    " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
    " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
    " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]\n",
    "```\n",
    "\n",
    "You'll notice that the reaction and the manifestation of that action are lists.  You only need to capture the first reaction and the first manifestation of the action.  That is, if there is a list of things, just output the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "ALLERGIES_FILE=\"/data/allergies.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def allergy_list(json_file):\n",
    "    \"\"\"(json_file)->str this function converts a json file to a list of patients' allergies and reactions. \"\"\"\n",
    "    pt = []\n",
    "    name = []\n",
    "    allergen= []\n",
    "    resource={}\n",
    "    reaction=[]\n",
    "    rec_def={}\n",
    "    m={}\n",
    "    ma=[]\n",
    "    r=[]\n",
    "    allergy=[]\n",
    "    patient=[]\n",
    "    output=[]\n",
    "    allergy_list=[]\n",
    "       \n",
    "         \n",
    "    with open(json_file) as f:\n",
    "        allergies=json.load(f)\n",
    "        \n",
    "    for entry in allergies.get('entry'):\n",
    "        patient=entry.get('resource').get('patient').get('display')\n",
    "        substance=entry.get('resource').get('substance').get('text')\n",
    "        resource=entry['resource']\n",
    "        rec_list=resource['reaction']\n",
    "        rec_dic= dict(rec_list[0])\n",
    "        m=rec_dic.get('manifestation')\n",
    "        m2=dict(m[0])\n",
    "        reaction=m2.get('text')\n",
    "        #output=patient +','+ ' '+ substance+ ','+' ' + reaction\n",
    "        #allergy_list.append(output)\n",
    "        output.append([patient,substance,reaction])\n",
    "    return output\n",
    "               \n",
    "        \n",
    "             \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
       " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
       " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
       " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergy_list(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2-tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "output=[['Jason Argonaut', 'PENICILLIN G', 'Hives'],\n",
    " ['Paul Boal', 'PENICILLIN G', 'Bruising'],\n",
    " ['Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS', 'Itching'],\n",
    " ['Jason Argonaut', 'STRAWBERRY', 'Anaphylaxis']]\n",
    "\n",
    "assert allergy_list(ALLERGIES_FILE) == output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-question",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 30.5 Allergy Reaction\n",
    "\n",
    "Write a function called `allergy_reaction(json_file,patient,substance)` that takes three parameter and returns the reaction that will happen if the patient takes the specified substance.  Solve this, in part, by calling your `allergy_list` function inside your new `allergy_reaction` function.\n",
    "\n",
    "If the substance is not found in the allergy list, the function should return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "ALLERGIES_FILE=\"/data/allergies.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def allergy_reaction(json_file, patient, substance):\n",
    "     \"\"\" (json_file, str, str)-> \n",
    "     This function utilizes the allergy_list function to define a reaction a patient would have if they were exposed to a specific substance. \"\"\"\n",
    "    al_l=[]\n",
    "    al=allergy_list(json_file)\n",
    "    al_l.append(al)\n",
    "    reac_l=[]\n",
    "    op=al_l[0]\n",
    "    patient = op[0]\n",
    "    sub= op[1]\n",
    "    r=zip(op[::1])\n",
    "    for substance in al_l:\n",
    "        if substance in substance:\n",
    "            x= al_l(output[reaction])\n",
    "        else:\n",
    "            x= None\n",
    "        \n",
    "   \n",
    "        reac_l.append(patient, substance,)\n",
    "        \n",
    "        result=((r)==x)\n",
    "        print(result)\n",
    "        return result\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def allergy_reaction(json_file, patient, substance):\n",
    "    \"\"\" (json_file, str, str)-> This function utilizes the allergy_list function to define a reaction a patient would have if they were exposed to a specific substance. \"\"\"\n",
    "    rl=[]\n",
    "    allergy_list(json_file)\n",
    "        #allergy_list=allergy_list(json_file)- continued to get error message-UnboundLocalError: local variable 'allergy_list' referenced before assignment\n",
    "    def output (patient, substance, reaction):\n",
    "        op=allergy_list(output[0], output[1], output[2])\n",
    "        for s in op['substance']:\n",
    "            if substance=='substance':\n",
    "                x=output['reaction']\n",
    "            else:\n",
    "                x=None\n",
    "            rl.append((patient, substance)==x)\n",
    "            print(rl)\n",
    "            return rl\n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print(patient\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "   for  in allergy_list(json_file):\n",
    "        output=allergy_list('output')\n",
    "        patient= allergy_list(output[0])\n",
    "        substance=allery_list(output[1])\n",
    "        reaction=allergy_list(output[2])\n",
    "    print(patient\n",
    "\n",
    "\n",
    "ef grades_sum(scores):\n",
    "    sum1 = 0\n",
    "    for i in scores:\n",
    "        sum1 = sum1 + i\n",
    "    print sum1\n",
    "    return sum1\n",
    "\n",
    "grades_sum([100, 100, 90, 40, 80, 100, 85, 70, 90, 65, 90, 85, 50.5])\n",
    "\n",
    "def grades_average(grades):\n",
    "\n",
    "    average = grades_sum(grades)/float(len(grades))\n",
    "\n",
    "    print average\n",
    "\n",
    "    return average\n",
    "\n",
    "grades_average([100, 100, 90, 40, 80, 100, 85, 70, 90, 65, 90, 85, 50.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "allergy_reaction() missing 2 required positional arguments: 'patient' and 'substance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4708810d9271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mallergy_reaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALLERGIES_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: allergy_reaction() missing 2 required positional arguments: 'patient' and 'substance'"
     ]
    }
   ],
   "source": [
    "allergy_reaction(ALLERGIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q3-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN G') == 'Hives'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'SHELLFISH-DERIVED PRODUCTS') == 'Itching'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'STRAWBERRY') == 'Anaphylaxis'\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Jason Argonaut', 'PENICILLIN') == None\n",
    "assert allergy_reaction(ALLERGIES_FILE, 'Paul Boal', 'PENICILLIN G') == 'Bruising'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Stretch (Extra) Problems\n",
    "\n",
    "Work on either of the stretch problems below can earn you up to 25 free points toward the midterm assignment.  That is, if you complete one of these extra problems successfully, you can skip 1 of the problems that will appear on the midterm exam coming up next week.\n",
    "\n",
    "The midterm will be distribute this Saturday 3/13.\n",
    "\n",
    "This assignment is due on Sunday 3/14.  If you are trying for one of these extra problems Slack me, and I'll provide you feedback on how you did on these before end of day Monday 3/15.  That way you can choose what to complete on the midterm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### STRETCH for March 2021 - For those looking for an additional challenge\n",
    "\n",
    "As I've mentioned in class, CMS is now enforcing a rule around price transparency.  Every facility that take Medicare payments is required to publish a \"machine readable\" file with it's pricing infomration for a number of common procedures across all of the payers they work with.  There are two examples of such files in the `/data/` directory: `whiteriver.json` and `saline.xml`.\n",
    "\n",
    "If you want to compare contracted prices across these two hospitals, you'll need to read in the information from both of those files into some kind of data structure, then merge the data together from those two files.  See what you can do.\n",
    "\n",
    "See if you can create an output file that has the following fields:\n",
    "* HOSPITAL\n",
    "* PROCEDURE_CODE\n",
    "* PAYER\n",
    "* AMOUNT\n",
    "\n",
    "If you choose to work on this, you may get stuck at some point and you won't know if you're _doing it right_. Make some assumptions. Document your questions in this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### STRETCH from March 2020 - For those looking for an additional challenge\n",
    "\n",
    "The Coronavirus is creating quite the stir right now.  There are some sources suggesting that trends show it is going to be significantly more serious than SARS was back in the 2002 timeframe.  Here's one visualization trying to demonstrate that: https://www.reddit.com/r/China_Flu/comments/ev2b4v/i_updated_some_charts_comparing_this_outbreak/\n",
    "\n",
    "Someone on Kaggle has generously already compiled a dataset based on information from Johns Hopkins about the Coronavirus outbreak.  https://www.kaggle.com/brendaso/2019-coronavirus-dataset-01212020-01262020  Create a Kaggle account, if you don't already have one.  Download this data set and then upload it to your Jupyter Home folder.  (The \"up arrow\" button is for uploading a file.)\n",
    "\n",
    "Use Python's built-in `csv` module to read the data from this file and generate the following information: **what are the total confirmed cases in all of Mainland China as of the latest information in the data set?**  Some important things to note:\n",
    "* Each entry for a given city has the **cumulative** number of cases.  So that column is not additive (it cannot be summed).  You'll have to find a way to filter your data for the last day for each city, then total those up.\n",
    "* If you choose to parse the date column, you will want to lookup how to do that using Python's `datetime` module.  Especially the `strptime` function.  https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior  Hint: you can parse a date string in the format 2/17/2020 using the code below.  This link will tell you what things like `%m` and `%Y` mean.\n",
    "\n",
    "```\n",
    "from datetime import datetime\n",
    "d = datetime.strptime('2/17/2020', '%m/%d/%Y')\n",
    "```\n",
    "\n",
    "If you want to take this another step, **create a list of tuples that contain (observate date, total confirmed) totalled over all locations represented in the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "CoV= pd.pandas.read_csv('2019nC0vSUMMARY.csv')\n",
    "CoVChina=CoV[CoV[\"Country\"]==\"Mainland China\"]\n",
    "CoVCH2= CoVChina.groupby(by=\"Province/State\")\n",
    "#|print(CoVCH2.max())\n",
    "#Col=CoVCH2[\"Confirmed\"]\n",
    "#Col_max=Col.max\n",
    "Max_CoVCh=CoVCH2.max()\n",
    "Total_Confirmed_df= Max_CoVCh['Confirmed'].sum()\n",
    "print(Total_Confirmed)\n",
    "print(Max_CoVCh)\n",
    "\n",
    "#with open ('2019nC0vSUMMARY.csv') as csv_file:\n",
    " #   csv_reader(csv_file, delimiter=',')\n",
    "  #  line_count=0\n",
    "#CoV_df.head()\n",
    "#print(os.getcwd())\n",
    "#print(CoVCH2)\n",
    "(r'https://jupyter.slucor.net/user/skuca/lab/tree/hds5210-2021/week06/2019nC0vSUMMARY.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Save this note with Ctrl-S (or Cmd-S)\n",
    "2. Skip down to the last command cell (the one starting with `%%bash`) and run that cell.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"DO NOT REMOVE THIS LINE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "[main 73560a8] Submitting the week 6 programming assignment\n",
      " 1 file changed, 24 insertions(+), 24 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:skuca/hds5210-2021.git\n",
      "   db5af3d..73560a8  main -> main\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git pull\n",
    "git add week06_assignment_2.ipynb\n",
    "git commit -a -m \"Submitting the week 6 programming assignment\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "If the message above says something like _Submitting the week 6 programming assignment_ or _Everything is up to date_, then your work was submitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
